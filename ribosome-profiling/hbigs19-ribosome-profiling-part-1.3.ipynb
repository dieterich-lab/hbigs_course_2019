{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1.3: Ribo-seq quality control and downstream analysis of the Rp-Bp results\n",
    "\n",
    "Through these sections, you wil learn how to use `matplotlib` to visualise the results.\n",
    "\n",
    "## Sections:\n",
    "   - 1.3.1 Ribo-seq quality control how-to.\n",
    "   - 1.3.2 Preprocessing analysis: standard rpbp preprocessing and more.\n",
    "   - 1.3.3 Prediction analysis: understand the output of rpbp.\n",
    "\n",
    "## Questions & Objectives:\n",
    "   - Learn how to identify \"good quality\" Ribo-seq data.\n",
    "   - Learn how to visualise the results.\n",
    "   - Understand and use the output of rpbp (ORF predictions).\n",
    "\n",
    "### After I will be able to:\n",
    "   - run the rpbp downstream analysis pipeline and assess the quality of the data;\n",
    "   - use the ORF predictions for follow-up studies.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.1 Ribo-seq quality control how-to\n",
    "\n",
    "Depending on the efficiency of the rRNA removal step of the experimental protocol, small structured RNAs (rRNAs, tRNAs, or snoRNAs) may have to be removed in a first pre-processing step. The remaining reads are mapped using s splice-aware aligner (`STAR`), but reads can still map to multiple locations. Different strategies can be implemented to either rescue the reads, keep one primary alignment per read, or discard all multi-mapping reads altogether. Finally, only periodic reads are kept for the analysis. We will use the data from the output of `Flexbar` (reads filtered for quality, trimmed from adapters), `Bowtie2` (reads mapping to rRNA, clean reads), `STAR` (unique reads) and `rpbp` (periodic reads) to quantify the amount of reads filtered out at each step of the pipeline.\n",
    "\n",
    "In a high-quality Ribo-seq library, reads mostly map to coding sequences (CDS or Canonical) (typically >85%) and to the 5'UTR (up to 10%). A smaller proportion map to the 3'UTR. The amount of reads mapping to non-coding regions can vary, but in general the signal is not very strong. Using the results of the pipeline, we will explore how many ORFs are predicted in each regions. It is also possible to use other tools such as `bedtools coverage`, that uses the mapped data (before translation prediction).\n",
    "\n",
    "A characteristic feature of a high-quality Ribo-seq library is its read-length distribution, which typically peaks around 29 nt in eukaryotic organisms, however broader distributions can be observed under different protocols, depending on the nuclease treatment, the drugs/inhibitors used, *etc.* It is also known that different ribosomal conformation correspond to distinct read-length distributions, and that these can also be affected by ribosomes belonging to different pools (mitochondrial ribosomes were shown previously to display a bimodal distribution, compared to cytosolic-derived fragments). All these considerations must be taken into account when analysing the distribution of read lengths.\n",
    "\n",
    "We will briefly explore these and other aspects graphically, using the data from the example. We will be using the full data from 4 biological replicates. This data has been prepared before the course. As a self-guided learning exercise, you can try to use this notebook and perform the analysis of the downsampled data that we ran in the previous notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font color=red>**Note** The cells below contain \"code\", so we will need to run them one after the other.</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from argparse import Namespace\n",
    "\n",
    "import pbio.misc.logging_utils as logging_utils\n",
    "import pbio.misc.mpl_utils as mpl_utils\n",
    "import pbio.ribo.ribo_utils as ribo_utils\n",
    "\n",
    "args = Namespace()\n",
    "logger = logging_utils.get_ipython_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# graphics\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.ticker as mtick\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set({\"ytick.direction\": u'out'}, style='white') #color_codes=True, palette='muted')\n",
    "\n",
    "params = {\n",
    "   'axes.labelsize': 28,\n",
    "   'font.size': 28,\n",
    "   'legend.fontsize': 26,\n",
    "   'xtick.labelsize': 26,\n",
    "   'ytick.labelsize': 26,\n",
    "   \"lines.linewidth\": 2.5,\n",
    "   'text.usetex': True,\n",
    "   'figure.figsize': [12, 8],\n",
    "    'font.family': 'sans-serif',\n",
    "    'font.sans-serif': 'DejaVu Sans',\n",
    "    'mathtext.fontset': 'dejavusans'\n",
    "   }\n",
    "plt.rcParams.update(params)\n",
    "font = FontProperties().copy()\n",
    "\n",
    "args.fontsize = params['legend.fontsize']\n",
    "args.legend_fontsize = params['legend.fontsize']\n",
    "args.labelsize =params['axes.labelsize']\n",
    "\n",
    "import logging\n",
    "mpl_logger = logging.getLogger('matplotlib')\n",
    "mpl_logger.setLevel(logging.WARNING) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I/O - \"configuration file\" and parameters/options\n",
    "\n",
    "args.baseloc = '/beegfs/pub/hbigs_course_2019/ribosome-profiling/riboSeqHBIGS19-analysis/config'\n",
    "args.dirloc = '/beegfs/pub/hbigs_course_2019/ribosome-profiling/riboSeqHBIGS19-analysis/analysis'\n",
    "\n",
    "# config file for the project to read in the sample name map\n",
    "configs = {\n",
    "    'hbigs': os.path.join(args.baseloc, \"hbigs19.yaml\")\n",
    "}\n",
    "\n",
    "alignment_counts_files = {\n",
    "    'hbigs': os.path.join(args.dirloc, \"HBIGS19.read-filtering-counts.csv.gz\")\n",
    "}\n",
    "\n",
    "read_lengths = {\n",
    "    'hbigs': os.path.join(args.dirloc, \"HBIGS19.read-length-distributions-unique.csv.gz\")\n",
    "}\n",
    "\n",
    "periodic_lengths = {\n",
    "    'hbigs': os.path.join(args.dirloc, \"HBIGS19.periodic-length-and-offsets.csv.gz\")\n",
    "}\n",
    "\n",
    "counts = {\n",
    "    'hbigs': os.path.join(args.dirloc, \"HBIGS19.counts-per-frame.csv.gz\")\n",
    "}\n",
    "\n",
    "\n",
    "data = 'hbigs'\n",
    "title_str = 'Ribo-seq'\n",
    "\n",
    "args.without_rrna = False\n",
    "# args.without_rrna = True\n",
    "\n",
    "# customise scale\n",
    "ymax = 8.0e7\n",
    "ystep = 1.0e7\n",
    "ymax_without_rrna = 5.0e7\n",
    "ystep_without_rrna = 1.0e7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ FILTERING COUNT\n",
    "\n",
    "if args.without_rrna:\n",
    "    args.ymax = ymax_without_rrna\n",
    "    args.ystep = ystep_without_rrna\n",
    "else:\n",
    "    args.ymax = ymax\n",
    "    args.ystep = ystep\n",
    "\n",
    "\n",
    "args.alignment_counts_order = [\n",
    "    'raw_data_count', \n",
    "    'without_adapters_count', \n",
    "    'without_rrna_count', \n",
    "    'genome_count', \n",
    "    'unique_count', \n",
    "    'length_count'\n",
    "]\n",
    "\n",
    "args.alignment_counts_names = [\n",
    "    'Poor quality', \n",
    "    'Ribosomal', \n",
    "    'No alignment', \n",
    "    'Multimappers', \n",
    "    'Non-periodic', \n",
    "    'Usable'\n",
    "]\n",
    "\n",
    "args.without_rrna_order = [\n",
    "    'without_rrna_count', \n",
    "    'genome_count', \n",
    "    'unique_count', \n",
    "    'length_count'\n",
    "]\n",
    "\n",
    "args.without_rrna_names = [\n",
    "    \"No alignment\", \n",
    "    \"Multimappers\", \n",
    "    \"Non-periodic\", \n",
    "    \"Usable\"\n",
    "]\n",
    "\n",
    "if args.without_rrna:\n",
    "    args.alignment_counts_order = args.without_rrna_order\n",
    "    args.alignment_counts_names = args.without_rrna_names\n",
    "\n",
    "args.alignment_counts = alignment_counts_files[data]\n",
    "\n",
    "args.alignment_counts_order = args.alignment_counts_order[::-1]\n",
    "args.alignment_counts_names = args.alignment_counts_names[::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = \"Reading counts\"\n",
    "logger.info(msg)\n",
    "\n",
    "alignment_counts = pd.read_csv(args.alignment_counts)\n",
    "\n",
    "config = yaml.load(open(configs[data]), Loader=yaml.FullLoader)\n",
    "sample_name_map = ribo_utils.get_sample_name_map(config)\n",
    "\n",
    "alignment_counts = alignment_counts.sort_values('note').reset_index()\n",
    "\n",
    "names = alignment_counts['note']\n",
    "\n",
    "alignment_diff_counts = mpl_utils.get_diff_counts(alignment_counts[args.alignment_counts_order])\n",
    "df = pd.DataFrame(alignment_diff_counts)\n",
    "df.columns = args.alignment_counts_names\n",
    "df['name'] = names.reset_index(drop=True)\n",
    "\n",
    "df['display_name'] = df['name'].apply(lambda x: sample_name_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "pal = sns.palettes.color_palette(palette=\"Set3\", n_colors=len(args.alignment_counts_names))\n",
    "\n",
    "gap = .2\n",
    "yticks = np.arange(0, args.ymax, args.ystep)\n",
    "\n",
    "bars = mpl_utils.create_stacked_bar_graph(\n",
    "    ax,\n",
    "    alignment_diff_counts,\n",
    "    colors=pal,\n",
    "    x_tick_labels=df['display_name'],\n",
    "    y_ticks=yticks,\n",
    "    y_tick_labels=yticks,\n",
    "    gap=gap,\n",
    "    end_gaps=True,\n",
    "    stack_labels=args.alignment_counts_names,\n",
    "    y_title='Ribo-seq reads',\n",
    "    log=False,\n",
    "    font_size=args.fontsize,\n",
    "    label_font_size=args.labelsize,\n",
    "    edge_colors='1'\n",
    ")\n",
    "\n",
    "leg = ax.legend(bbox_to_anchor=(1, 0), \n",
    "                loc=\"lower left\",\n",
    "                bbox_transform=ax.transAxes, \n",
    "                columnspacing=0.5,\n",
    "                fontsize=args.legend_fontsize,\n",
    "                frameon=False,\n",
    "                ncol=1)\n",
    "\n",
    "if args.without_rrna:\n",
    "    ax.yaxis.set_major_formatter(mtick.FormatStrFormatter('%.0e'))\n",
    "else:\n",
    "    ax.yaxis.set_major_formatter(mtick.FormatStrFormatter('%.0e'))\n",
    "    \n",
    "mpl_utils.set_label_fontsize(ax, args.fontsize)\n",
    "mpl_utils.set_legend_title_fontsize(ax, args.fontsize)\n",
    "\n",
    "ax.set_title(title_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FOOTPRINT LENGTH DISTRIBUTION\n",
    "\n",
    "args.reads = read_lengths[data]\n",
    "args.periodic = periodic_lengths[data]\n",
    "args.out = read_lengths[data]\n",
    "\n",
    "msg = \"Reading counts\"\n",
    "logger.info(msg)\n",
    "\n",
    "reads = pd.read_csv(args.reads, sep=',')\n",
    "periodic = pd.read_csv(args.periodic, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_samples = ['EGF', 'PBS'] # the two conditions\n",
    "all_lengths_list = []\n",
    "for sample in subset_samples:\n",
    "    m_subset = periodic['condition'].str.contains('^'+sample)\n",
    "    periodic_sub = periodic[m_subset]\n",
    "\n",
    "    all_lengths = defaultdict(list) \n",
    "    all_names = periodic_sub['condition'].unique()\n",
    "    for name in all_names:\n",
    "        lengths = [str(l) for l in periodic_sub[periodic_sub['condition']==name].lengths.values]\n",
    "        for l in lengths:\n",
    "            all_lengths[l].append(reads[reads['condition']==name][lengths[lengths.index(l)]].values[0])\n",
    "\n",
    "    all_lengths_df = pd.DataFrame.from_dict(all_lengths, orient='index').T.unstack().reset_index() \n",
    "    all_lengths_df['Model'] = sample\n",
    "    all_lengths_list.append(all_lengths_df)\n",
    "    \n",
    "all_lengths_df = pd.concat(all_lengths_list)\n",
    "all_lengths_df = all_lengths_df[~all_lengths_df[0].isna()].copy()\n",
    "all_lengths_df.rename(columns={'level_0':'Periodic footprint length (nt)', 0:'Ribo-seq reads'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "pal = sns.palettes.color_palette(palette=\"Set3\", n_colors=6)\n",
    "pal = [pal[4], pal[3]]\n",
    "\n",
    "flatui = [\"#3498db\", \"#e74c3c\"] # \"#95a5a6\" \"##9b59b6\"\n",
    "hue_palette = sns.color_palette(flatui)\n",
    "\n",
    "# sns.catplot(x=\"level_0\", y=0, kind=\"swarm\", data=df)\n",
    "g = sns.swarmplot(x=\"Periodic footprint length (nt)\", y='Ribo-seq reads', data=all_lengths_df, color=pal[0], size=8, ax=ax,\n",
    "                 edgecolor=pal[0], hue='Model', hue_order=subset_samples, \n",
    "                  palette=hue_palette)\n",
    "\n",
    "leg = ax.legend(loc=\"upper right\",\n",
    "                columnspacing=0.5,\n",
    "                fontsize=params['legend.fontsize'],\n",
    "                frameon=False,\n",
    "                ncol=1)\n",
    "\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # COUNTS PER FRAME\n",
    "\n",
    "args.counts = counts[data]\n",
    "\n",
    "msg = \"Reading counts\"\n",
    "logger.info(msg)\n",
    "\n",
    "frame_counts = pd.read_csv(args.counts)\n",
    "    \n",
    "frame_counts = frame_counts.sort_values('condition').reset_index()\n",
    "\n",
    "# From raw value to percentage\n",
    "\n",
    "totals = [i+j+k for i,j,k in zip(frame_counts['frame_count'], frame_counts['frame+1_count'], frame_counts['frame+2_count'])]\n",
    "frame1 = [i / j * 100 for i,j in zip(frame_counts['frame_count'], totals)]\n",
    "frame2 = [i / j * 100 for i,j in zip(frame_counts['frame+1_count'], totals)]\n",
    "frame3 = [i / j * 100 for i,j in zip(frame_counts['frame+2_count'], totals)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "pal = sns.palettes.color_palette(palette=\"Set3\", n_colors=6)\n",
    "\n",
    "names = frame_counts['condition']\n",
    "r = range(len(names))\n",
    "\n",
    "barWidth = .95\n",
    "ax.bar(r, frame1, color=pal[0], edgecolor='white', width=barWidth, label='Reading frame')\n",
    "ax.bar(r, frame2, bottom=frame1, color=pal[1], edgecolor='white', width=barWidth, label='Reading frame +1')\n",
    "ax.bar(r, frame3, bottom=[i+j for i,j in zip(frame1,frame2)], color=pal[2], edgecolor='white', width=barWidth, label='Reading frame +2')\n",
    "plt.xticks(r, names, rotation='vertical')\n",
    "# ax.set_ylabel('Periodic,\\nP-site shifted reads (\\%)')\n",
    "ax.set_ylabel('P-sites (\\%)')\n",
    "ax.legend(loc='upper right',\n",
    "             bbox_to_anchor=(1.45, 1.),\n",
    "    ncol=1,\n",
    "    frameon=False,\n",
    "    framealpha=0.9\n",
    ")\n",
    "ax.set_title(title_str)\n",
    "sns.despine(left=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing analysis\n",
    "***\n",
    "\n",
    "In addition to the above, the `create-rpbp-preprocessing-report` script can be used to generate a latex document and several plots that summarize the preprocessing and ORF profile construction (among which you will recognise the first figure above).\n",
    "\n",
    "We have ran this script on the data, and we will examine the report.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***\n",
    "\n",
    "MIT License (code and scripts)\n",
    "\n",
    "Copyright (c) 2019 Etienne Boileau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "devc3.6",
   "language": "python",
   "name": "devc3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
