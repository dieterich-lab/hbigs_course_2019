{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1.1: Virtual environments and installation of packages hosted on GitHub\n",
    "\n",
    "## Sections:\n",
    "   - 1.1.1 Short introduction to Python virtual environments: how does a virtual environments work, installing and using a virtual environment.\n",
    "   - 1.1.2 Installation of packages hosted on GitHub.\n",
    "   - 1.1.3 Short introduction to Jupyter (Notebook) and the JupyterHub\n",
    "   \n",
    "## Questions & Objectives:\n",
    "   - Why do we need a virtual environment?\n",
    "   - Learn how to install and use a Python virtual environment.\n",
    "   - Learn how to install a package hosted on GitHub, in particular how to install the rpbp package.\n",
    "   - Jupyter Notebook basics: dashboard, user interface, navigation, running code, etc. How to use Jupyter with virtual environments.\n",
    "   - How to use the JupyterHub.\n",
    "   \n",
    "### After I will be able to:\n",
    "   - create and use a Python virtual environment to install packages.\n",
    "   - understand what is a Jupyter Notebook, and how to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1.1 Short introduction to Python virtual environments\n",
    "\n",
    "A *virtual environment* is a tool to help you keep dependencies and packages required by different projects separate and isolated from the system-wide installation.\n",
    "\n",
    "### Why do we need a virtual environment? \n",
    "***\n",
    "    \n",
    "Imagine a scenario where you need different versions of the same package, say v1.8 and v2.5. These would normally reside in the same directory with the same name...\n",
    "\n",
    "    Virtual environments enable to isolate different versions of the same package (if they live in different environments, say myproject1.8 and myproject2.5).\n",
    "    \n",
    "Imagine a scenario where things go wrong (you break something, install many conflicting packages) ... \n",
    "\n",
    "    Virtual environments can be deleted and re-created easily without affecting your system or the other packages that are installed outside.\n",
    "    \n",
    "Imagine a scenario where you cannot install packages system-wide or do not want to do it...\n",
    "\n",
    "    Virtual environments enable you to install everything that you want, without affecting the system or other packages that are installed outside.\n",
    "    \n",
    "    \n",
    "### How does a virtual environment work?\n",
    "***\n",
    "\n",
    "We use a module named `venv` which is a tool to create isolated Python environments. A virtual environment is a directory tree (a folder structure) which contains Python executables and other necessary files. These are ideally isolated from system site directories. Each virtual environment has its own Python installation and can have its own independent set of installed Python packages.\n",
    "\n",
    "When working in a command shell, to create a virtual environment (assuming you have Python3 installed!):\n",
    "\n",
    "`\n",
    "python3 -m venv /path/to/new/virtual/environment\n",
    "`\n",
    " \n",
    "To activate the new virtual environment:\n",
    "\n",
    "`\n",
    "source /path/to/virtual/environment/bin/activate\n",
    "`\n",
    "\n",
    "### Let's try it!\n",
    "***\n",
    "\n",
    "We will create a fresh virtual environment and eventually install packages using the script `ribo-setup`, located\n",
    "under *hbigs_course_2019/ribosome-profiling*.\n",
    "\n",
    "\n",
    "### More\n",
    "***\n",
    "\n",
    "For information about Python virtual environments, see the [venv](https://docs.python.org/3/library/venv.html#module-venv) documentation. See also [PEP 405](https://www.python.org/dev/peps/pep-0405/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1.2 Installation of packages hosted on GitHub\n",
    "\n",
    "### What is GitHub?\n",
    "***\n",
    "\n",
    "Git is an open-source version control system, *i.e.* used to track changes to documents/code for yourself or amongst collaborators, releasing versions, *etc.* GitHub.com is where (mostly) developers store their projects, and render them accessible to the community. Anyone (even people who have nothing to do with the development of a project) can download the files and use them (according to the license, *e.g* the `rpbp` package, as well as these notebooks/scripts and the original material for this part of the course is under the MIT license). Project files are\n",
    "stored in a particular location, referred to as a repository (usually abbreviated to *repo*), and you can access it with a unique URL. \n",
    "\n",
    "### How to install a package hosted on GitHub?\n",
    "***\n",
    "\n",
    "Some packages hosted on GitHub can be installed via package-management systems (`pip` for Python, RStudio Package Manager, *etc.*). In these cases, you may not even know that the source codes for these packages \"live\" on GitHub. Sometimes, however, you need to install the package by first *cloning* the repository and following specific instructions.\n",
    "\n",
    "![](img/git-1.png)\n",
    "\n",
    "\n",
    "### Let's try it!\n",
    "***\n",
    "\n",
    "After creating a new virtual environment for this part of the course, we will install the `rpbp` and `slurm-magic` packages using the script `ribo-setup`, located under *hbigs_course_2019/ribosome-profiling*.\n",
    "\n",
    "\n",
    "### More\n",
    "***\n",
    "\n",
    "In the last part of the course, we will go through a collection of explanations and short practical exercises about version control (Git and GitHub) and open source software. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1.3 Short introduction to Jupyter (Notebook) and the JupyterHub\n",
    "\n",
    "The Jupyter Notebook is an open-source web-based application allowing in-browser editing (Jupyter is running on your own computer, *i.e* your computer acts as the server), combining text, code, computations and rich media output (notebook documents). Jupyter supports many programming languages, including Python, R, and Julia. The JupyterHub is a multi-user version of the Notebook (this notebook is served via \"our Hub\" `https://jupyter.dieterichlab.org:49200`).\n",
    "\n",
    "### Basic workflow\n",
    "***\n",
    "\n",
    "Typically, a notebook document is organised into cells, and one moves forward from one cell to the next, breaking the content or the computation into separate parts. This workflow allows to \"validate\" the output of one cell before moving to the next, and is also convenient for interactive exploration.\n",
    "\n",
    "### Jupyter Notebook basics\n",
    "***\n",
    "\n",
    "The Notebook dashboard: when you first start the notebook server, your browser will open to the notebook dashboard. To create a new notebook, click on the \"New\" button and select a kernel from the dropdown menu. The running notebooks are shown with a green icon and text (or via the \"Running tab\"). Notebooks remain running until you explicitly shut them down; closing the notebook's page is not sufficient. \n",
    "   \n",
    "![](img/jupyter-1.png)\n",
    "    \n",
    "To shutdown, delete, duplicate, or rename a notebook check the checkbox next to it. You can also perform these operations and more directly on the running notebook by using the top menu and tool bar (see at the top of this notebook!) \n",
    "\n",
    "![](img/jupyter-2.png)\n",
    "\n",
    "Modal editor: **edit mode**. Edit mode is indicated by a green cell border and a prompt showing in the editor area. When a cell is in edit mode, you can type into the cell, like a normal text editor. Enter edit mode by pressing `Enter` or using the mouse to click on a cell.\n",
    "\n",
    "![](img/jupyter-3.png)\n",
    "\n",
    "Modal editor: **command mode**. Command mode is indicated by a grey cell border with a blue left margin. When you are in command mode, you are able to edit the notebook as a whole, but not type into individual cells (be careful to type into a cell in command mode!). Enter command mode by pressing `Esc` or using the mouse to click outside a cell.\n",
    "    \n",
    "![](img/jupyter-4.png)\n",
    "\n",
    "### Basic commands\n",
    "***\n",
    "\n",
    "Edit mode\n",
    "\n",
    "| Command | action |\n",
    "|------|------|\n",
    "|   `Ctrl-Enter`  | run selected cells |\n",
    "|   `Shift-Enter`  | run cell, select below |\n",
    "\n",
    "Command mode\n",
    "\n",
    "| Command | action |\n",
    "|------|------|\n",
    "|   `Enter`  | enter edit mode |\n",
    "|   `Esc`  | enter command mode |\n",
    "|   `a`  | insert cell above |\n",
    "|   `b`  | insert cell below |\n",
    "\n",
    "\n",
    "## More\n",
    "***\n",
    "\n",
    "- See [Project Jupyter](https://jupyter.org/) for installation instructions, detailed documentation, *etc.*\n",
    "- After the course, explore the menu (Help) of this notebook, and experiment with basic commands.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use Jupyter with virtual environments\n",
    "\n",
    "We will now go back to your Desktop, open an `LXTerminal` and navigate to the directory for this part of the course by typing: \n",
    "\n",
    "`\n",
    "cd ~/hbigs_course_2019/ribosome-profiling\n",
    "`\n",
    "\n",
    "You will see there this notebook and others, as well as a file called `ribo-setup`. We will run this script to create a new virtual ennvironment, clone the `rpbp` and `slurm-magic` repositories, install the packages and add a jupyter kernel for the newly created environment. To run the script from the terminal, type:\n",
    "\n",
    "`\n",
    "chmod +x ribo-setup; ./ribo-setup\n",
    "`\n",
    "\n",
    "When the script has finished running, we will need to (1) refresh the page, (2) go to \"Kernel\" in the top menu bar, (3) \"Change kernel\" in the dropdown menu list, and then select `hbigs19-ribo`, which is the name of our newly created environment.\n",
    "\n",
    "![](img/jupyter-5.png)\n",
    "\n",
    "\n",
    "We are now ready to go...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1.2: Introduction to ribosome-profiling (Ribo-seq) and the Rp-Bp workflow\n",
    "\n",
    "For practical reasons, we will cover some technical aspects before introducing ribosome-profiling in more details. In particular, we will first set-up our notebook to run `rpbp` on the example Ribo-seq dataset, briefly introduce the `Slurm` workload manager (via `slurm-magic`), and actually run the `rpbp` pipeline. While our data is running, we will then go into more details about Ribo-seq, the `rpbp` package and some methodological aspects behind it.\n",
    "\n",
    "## Sections:\n",
    "\n",
    "   - 1.2.1 Overview of the `rpbp` pipeline: command line options and configuration file\n",
    "   - 1.2.2 Very short introduction to the `Slurm` workload manager (`slurm-magic`), used to run the rpbp pipeline\n",
    "   \n",
    "   \n",
    "   - 1.2.3 High-level introduction to Ribo-seq, de novo ORF discovery (elements of annotation, transcript isoforms, CDS, UTRs, etc.), biological relevance of alternative translation events (including translation from non-coding transcripts), and why we need \"dedicated software\" to analyse Ribo-seq data.\n",
    "   - 1.2.4 The `rpbp` pipeline step-by-step:\n",
    "         - Creating reference genome indices;\n",
    "         - Running the pipeline: creating ORF profiles, predicting translated ORFs.\n",
    "\n",
    "## Questions & Objectives:\n",
    "   - What is the translatome? What are the uses of Ribo-seq.\n",
    "   - Why do we need dedicated software to analyse Ribo-seq data?\n",
    "   - What softwares are available to analyse Ribo-seq data?\n",
    "   - Understand how to use the `rpbp` package (on my laptop, on the cluster using the `Slurm` workload manager).\n",
    "   - Run the complete rpbp pipeline on a selected Ribo-seq dataset.\n",
    "   \n",
    "### After I will be able to:\n",
    "   - understand how to analyse Ribo-seq data for ORF discovery;\n",
    "   - run the rpbp package (only ORF profiles, or full pipeline)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.1 Overview of the rpbp pipeline: command line options and configuration file\n",
    "\n",
    "The `rpbp` pipeline consists of an index creation step, which must be performed once for each genome and set of annotations, and a two-phase prediction pipeline, which must be performed for each sample. In the first phase of the prediction pipeline, a ORF profiles are created. In the second phase, the ORFs which show evidence of translation are identified.\n",
    "\n",
    "### Creating reference genome indices\n",
    "***\n",
    "\n",
    "The entire index creation process can be run automatically using the following command:\n",
    "\n",
    "`\n",
    "prepare-rpbp-genome <config> [--overwrite] [logging options] [processing options]\n",
    "`\n",
    "\n",
    "See [Creating reference genome indices](https://rp-bp.readthedocs.io/en/latest/usage-instructions.html#creating-reference-genome-indices) for detailed information. To save time, we have already created the indices for the human genome (GRCh38.96). Go to your `LXTerminal` and navigate to these files\n",
    "\n",
    "`\n",
    "cd ~/hbigs_course_2019/ribosome-profiling/genomes\n",
    "`\n",
    "\n",
    "We will briefly explain the index creation step by examining these files.\n",
    "\n",
    "\n",
    "### Running the pipeline\n",
    "***\n",
    "\n",
    "The entire `rpbp` pipeline (2 steps) can be run on a set of riboseq samples, including any biological replicates. To run the pipeline, we first need to prepare a configuration file, consisting in a series of required (and optional) key: value pairs. We will explain this below.\n",
    "\n",
    "Lastly, to run the pipeline on the cluster, we will use the `Slurm` workload manager. `Slurm` is a job scheduler. For our purpose, it suffices to know that it provides a framework to ask for resources and execute our job on the cluster. To submit our job, we will use the command `sbatch`, and to monitor the status of our job, we will use `squeue -u username`. We will actually use `slurm-magic` commands, which implement special commands to interact with `Slurm`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font color=red>**Note** The cells below contain \"code\", so we will need to run them one after the other.</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules that are needed to run this notebook\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%load_ext slurm_magic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some functions, definitions, etc. that are needed to run this notebook\n",
    "\n",
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "@register_line_cell_magic\n",
    "def writefile_globals(line, cell):\n",
    "    with open(line, 'w') as f:\n",
    "        f.write(cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $PATH is an environment variable related to file location that are typically used to run programs.\n",
    "# When one types a command to run, the system looks for this command in the directories specified by $PATH.\n",
    "\n",
    "# What is on you $PATH?\n",
    "!echo $PATH \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will now add the location of certain programs that are required to our $PATH,\n",
    "# including executable scripts that were installed with the rpbp package.\n",
    "\n",
    "# Advanced note: sys.path does not contain path to virtual environment executables, and adding to sys.path\n",
    "# does not solve the problem...\n",
    "\n",
    "# first find where we are, we use the same structure as in \"ribo-setup\" \n",
    "HOME = !echo $HOME\n",
    "HOME = HOME.n\n",
    "PARENT = HOME + '/hbigs_course_2019/ribosome-profiling'\n",
    "# this is the location where rpbp-related executables were installed\n",
    "ENVLOC = PARENT + '/envs/hbigs19-ribo/bin'\n",
    "# these are standard bioinformatics tools that you have already used, which are installed\n",
    "# at these locations on the cluster, we use specific versions to be compatible with the rpbp package\n",
    "add2path = ['/biosw/slurm/18.08.6.2/bin',\n",
    "            '/biosw/bowtie2/2.3.0',\n",
    "            '/biosw/star/2.6.1d',\n",
    "            '/biosw/samtools/1.7/bin',\n",
    "            '/biosw/flexbar/3.5.0']\n",
    "add2path.append(ENVLOC)\n",
    "\n",
    "PATH = !echo $PATH\n",
    "PATH.extend(add2path)\n",
    "PATH = ':'.join(PATH)\n",
    "# out updated $PATH is...\n",
    "%set_env PATH=$PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare to run the example (downsampled) dataset: 4 replicates, 2 PBS, 2 EGF.\n",
    "# change directory\n",
    "DIRLOC = PARENT + '/riboSeqHBIGS19-downsampled-analysis'\n",
    "CFG = DIRLOC + '/config'\n",
    "RES = DIRLOC + '/riboseq-results'\n",
    "%cd $CFG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first need to prepare a YAML configuration file to run the rpbp package. \n",
    "# YAML (\"YAML Ain't Markup Language\") is a data-serialization (markup) language.\n",
    "\n",
    "# We will do this below and explain the structure of the config file. Please check that\n",
    "# the file has been correctly written to disk under /riboSeqHBIGS19-downsampled-analysis/config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile_globals hbigs19-downsampled.yaml\n",
    "\n",
    "project_name: HBIGS19-downsampled\n",
    "\n",
    "# Base location for the created index files.=\n",
    "genome_base_path: /beegfs/pub/hbigs_course_2019/ribosome-profiling/genomes/homo_sapiens/GRCh38_96\n",
    "    \n",
    "# An identifier which will be used in the filenames. This should not contain\n",
    "# spaces, forward slashes, or other special characters.\n",
    "genome_name: GRCh38.96\n",
    "    \n",
    "# The full path to the GTF file which contains the exon and CDS annotations.\n",
    "gtf: /beegfs/pub/hbigs_course_2019/ribosome-profiling/genomes/homo_sapiens/GRCh38_96/GRCh38.96.gtf\n",
    "\n",
    "# The fasta file which contains the genome. The genomic identifiers in the GTF and\n",
    "# fasta files must match (e.g., \"I\" and \"I\", or \"chrI\" and \"chrI\", but not \"I\" and \"chrI\").\n",
    "fasta: /beegfs/pub/hbigs_course_2019/ribosome-profiling/genomes/homo_sapiens/GRCh38_96/GRCh38_96.fa\n",
    "\n",
    "# The base location for the STAR genome index.\n",
    "star_index: /beegfs/pub/hbigs_course_2019/ribosome-profiling/genomes/homo_sapiens/GRCh38_96/star\n",
    "\n",
    "# The base location for the Bowtie2 index for the ribosomal sequences.\n",
    "ribosomal_index: /beegfs/pub/hbigs_course_2019/ribosome-profiling/genomes/homo_sapiens/rRNA_cluster_plus_mtRNA/rRNA_cluster_plus_mtRNA\n",
    "# The fasta file containing the rRNA sequences. The file can also contain other\n",
    "# sequences which should be filtered, such as tRNA or snoRNAs\n",
    "ribosomal_fasta: /beegfs/pub/hbigs_course_2019/ribosome-profiling/genomes/homo_sapiens/rRNA_cluster_plus_mtRNA/rRNA_cluster_plus_mtRNA.fasta\n",
    "\n",
    "# A file containing standard adapters.\n",
    "adapter_file: /beegfs/pub/hbigs_course_2019/ribosome-profiling/genomes/riboseq-adapters.fa\n",
    "\n",
    "# The base location for the created files\n",
    "riboseq_data: {RES}\n",
    "\n",
    "# A dictionary in which each entry specifies a sample. The key is an \n",
    "# informative name about the sample, and the value gives the complete path to \n",
    "# the sequencing file (a fastq(.gz) file). The names will be used to \n",
    "# construct filenames, so they should not contain spaces, forward slashes, or \n",
    "# other special characters.\n",
    "riboseq_samples:\n",
    " dSRR7451194.EGF.rep-1: /beegfs/pub/hbigs_course_2019/raw-data/downsampled/dSRR7451194_1.fastq.gz\n",
    " dSRR7451184.EGF.rep-2: /beegfs/pub/hbigs_course_2019/raw-data/downsampled/dSRR7451184_1.fastq.gz\n",
    " dSRR7451191.PBS.rep-1: /beegfs/pub/hbigs_course_2019/raw-data/downsampled/dSRR7451191_1.fastq.gz\n",
    " dSRR7451197.PBS.rep-2: /beegfs/pub/hbigs_course_2019/raw-data/downsampled/dSRR7451197_1.fastq.gz\n",
    "\n",
    "riboseq_biological_replicates:\n",
    " EGF:\n",
    "  - dSRR7451194.EGF.rep-1\n",
    "  - dSRR7451184.EGF.rep-2\n",
    " PBS:\n",
    "  - dSRR7451191.PBS.rep-1\n",
    "  - dSRR7451197.PBS.rep-2\n",
    "\n",
    "riboseq_sample_name_map:\n",
    " dSRR7451194.EGF.rep-1: EGF1\n",
    " dSRR7451184.EGF.rep-2: EGF2\n",
    " dSRR7451191.PBS.rep-1: PBS1\n",
    " dSRR7451197.PBS.rep-2: PBS2\n",
    "\n",
    "# Rp-Bp options: we need to change the default parameters to run the downsampled data.\n",
    "# Generally, you do not need to change the default parameters!\n",
    "\n",
    "# The number of bases upstream of the translation initiation site to begin \n",
    "# constructing the metagene profile.\n",
    "metagene_start_upstream: 50\n",
    "# The number of bases downstream of the translation initiation site to end \n",
    "# the metagene profile.\n",
    "metagene_start_downstream: 50\n",
    "# The number of bases upstream of the translation termination site to begin \n",
    "# constructing the metagene profile.\n",
    "metagene_end_upstream: 50\n",
    "# The number of bases downstream of the translation termination site to end \n",
    "# the metagene profile.\n",
    "metagene_end_downstream: 50\n",
    "\n",
    "# N.B. These values are set artificially low for the example to work!\n",
    "min_metagene_profile_count: 50\n",
    "min_metagene_image_count: 10\n",
    "\n",
    "# N.B. These value are set low to reduce the running time, but will affect the results.\n",
    "metagene_iterations: 100\n",
    "translation_iterations: 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are now ready to submit our job. We use the Slurm workload manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH -J \"hbigs19\"\n",
    "#SBATCH -n 1\n",
    "#SBATCH -N 1\n",
    "#SBATCH -c 1\n",
    "#SBATCH --mem=20G\n",
    "\n",
    "run-all-rpbp-instances hbigs19-downsampled.yaml \\\n",
    "    --merge-replicates \\\n",
    "    --run-replicates \\\n",
    "    --keep-intermediate-files \\\n",
    "    --num-cpus 12 \\\n",
    "    --mem 120G \\\n",
    "    --use-slurm \\\n",
    "    --logging-level INFO \\\n",
    "    --log-file hbigs19-downsampled.log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We check that our job is actually running...\n",
    "%squeue -u course01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.3 High-level introduction to Ribo-seq\n",
    "\n",
    "The idea behind the Ribo-seq protocol can be summarised in a few lines: ribosome-protected fragments or footprints (RNA protected by the ribosome), can be isolated through the use of nucleases that degrade unprotected RNA regions, and submitted to a deep sequencing protocol similar to those used for RNA. In brief, *(i)* ribosome-bound RNA is isolated from cell/tissue lysates; *(ii)* treated with a drug, depending on the purpose of the experiment, *e.g* elongating (cycloheximide) or initiating ribosomes (harringtonine, lactimidomycin/puromycin), for eukaryotes, the choice of inhibitor has a concentration-dependent impact on the kinetics of initiation and elongation; *(iii)* nucleases are added to digest the unprotected RNA (RNase), the choice of nuclease and treatment strongly affect the ribosome profiles; *(iv)* after footprint recovery, rRNA depletion is performed and samples are sequenced, but protocols vary a lot (circularisation step or no, bias reduction methods, *etc*), and there are always new methods! ([Ligation-free ribosome profiling](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-016-1005-1), [RiboLace](https://www.sciencedirect.com/science/article/pii/S2211124718315444?via%3Dihub), to name but a few) \n",
    "\n",
    "By mapping the position of translating ribosomes over the entire transcriptome, Ribo-seq provides a snapshot of the entire translatome. Ribo-seq has been used to answer a wide range of questions, including identification of translated small open reading frames (ORFs), non-coding sequences and alternative reading frames, quantification of translational control (in combination with RNA-seq, *i.e* translational efficiency, or regulatory mechanisms associated with the translation process itself, such as upstream ORFs acting in cis, or translation regulating transcript stability by triggering NMD via recognition of a premature stop codon), or for gaining mechanistic insights on the translation process itself.\n",
    "\n",
    "### Open reading frame discovery\n",
    "***\n",
    "\n",
    "We understand an open reading frame (ORF) as a potentially translatable sequence that consists of a series of codons beginning with a start codon and ending with a stop codon. Translatable ORFs can be found anywhere: in the 5' untranslated region (5'UTR), in the 3' untranslated region (3'UTR), within or overlapping with annotated coding sequences (CDSs), in transcripts that were previously thought to be non-coding (lincRNAs, antisense, pseudogene, or other processed transcripts), or in novel transcripts (intra/intergenic).\n",
    "\n",
    "![](img/ribo-1.png)\n",
    "\n",
    "As we will briefly explain below, in the `rpbp` workflow, ORFs are labeled according to their position and exon structure relative to the annotations. Except for annotated CDSs (Canonical), the assignment of these labels depend on the complexity of the annotations, and thus are not \"fixed\".\n",
    "\n",
    "\n",
    "| Label | Description |\n",
    "|------|------|\n",
    "|   **Canonical**  |  An ORF that coincides with an annotated coding sequence (CDS from a protein coding transcript) |\n",
    "|   **Can. (variant)**  | An ORF that is in-frame (with respect to a CDS), N-terminus extended or truncated |\n",
    "|   **uORF** or five prime |  An ORF that is in the 5'UTR of a CDS and do not overlap other CDS on the same strand (from alternative transcripts) |\n",
    "|   **dORF** or three prime | An ORF that is in the 3'UTR of a CDS and do not overlap other CDS on the same strand (from alternative transcripts) |\n",
    "|   **ncORF** or noncoding | An ORF that originates from a transcript not annotated as coding (non-coding, processed transcript or pseudogene) |\n",
    "\n",
    "\n",
    "\n",
    "An overlapping uORF is an out-of-frame ORF overlapping on the same transcript both the 5'UTR and the canonical coding sequence. An overlapping dORF is an out-of-frame ORF overlapping on the same transcript both the 3'UTR and the canonical coding sequence. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Small open reading frames and biological relevance of alternative translation events\n",
    "***\n",
    "\n",
    "We refer to a small ORF (**sORF**) as an ORF that contains less than 100 amino acids. \n",
    "\n",
    "Accumulated evidence from Ribo-seq (and proteomics) experiments over the last 5 years suggests that small open reading frames-encoded peptides are underpredicted, even for well-annotated model species. sORFs can be found over a wide variety of transcripts. So far, a number of sORFs encoding functional peptides have been identified, such as Sarcolamban, Myoregulin, Myomixer, Minion, MOXI, MOTS-c, SPAR, or NoBody, to name but a few.\n",
    "\n",
    "\n",
    "Tools such as `rpbp` can be used as part of a *sORF discovery workflow*, as depicted below:\n",
    "\n",
    "\n",
    "\n",
    "![](img/ribo-2.png)\n",
    "\n",
    "\n",
    "### More\n",
    "***\n",
    "\n",
    "Many recent publications address the role of alternative translation events:\n",
    "- [S. van Heesch et al. The Translational Landscape of the Human Heart](https://www.sciencedirect.com/science/article/pii/S0092867419305082)\n",
    "- [J Ruiz-Orera & M. MarAlbà, Translation of Small Open Reading Frames: Roles in Regulation and Evolutionary Innovation](https://www.sciencedirect.com/science/article/pii/S0168952518302221)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why do we need \"dedicated software\" to analyse Ribo-seq data?\n",
    "***\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "******* workflow\n",
    "\n",
    "alba\n",
    "\n",
    "Figure 1. Workflow to Identify Actively Translated ORFs. Ribosome-protected RNA fragments are sequenced and\n",
    "mapped to all annotated transcripts in the species genome. On the basis of the three-nucleotide periodicity of the reads,\n",
    "and additional features, different software can predict actively translated ORFs. The prediction is based on a high fraction of\n",
    "reads in the correct frame (in-frame, blue colour) when compared to alternative ones (off-frame, red colour). This step is\n",
    "performed with single-nucleotide resolution after computing the read P-site per each read length. Abbreviations: ORF,\n",
    "open reading frame.\n",
    "\n",
    "\n",
    "** then methods\n",
    "\n",
    "\n",
    "How-\n",
    "ever, it has also been frequently shown that the ribosome\n",
    "occupancy itself, as indicated by the RPF reads mapped\n",
    "on the transcriptome, is not sufficient for calling of the\n",
    "active translation, given the possible noise from the data\n",
    "processing and experimental procedures, regulatory RNAs\n",
    "that bind with the ribosome, and ribosome engagement\n",
    "without translation (16,17). \n",
    "\n",
    "\n",
    "Owing to its subcodon resolution, ribosome profiling re-\n",
    "veals the precise locations of the peptidyl-site (P-site) of\n",
    "the 80S ribosome in the RPF reads, given that the exper-\n",
    "iment itself was properly performed and the RPF reads\n",
    "were correctly filtered. Aligned by their P-site positions, the\n",
    "RPF reads resulted from the translating ribosomes should\n",
    "therefore exhibit 3-nt periodicity along the ORF, which is\n",
    "the strongest evidence of active translation. Only recently\n",
    "have different strategies been developed to assess the trans-\n",
    "lation by testing the distribution of ribosome engagement\n",
    "at the subcodon resolution (11,12,18–23). These methods\n",
    "have been comprehensively reviewed in (24). Some of these\n",
    "methods used the strategy of machine learning, which re-\n",
    "quires prior annotation of the known coding transcripts\n",
    "for training of the model (12,21). Like many supervised\n",
    "methods in general, the results of these methods heavily\n",
    "rely on the pre-annotated training set, source of a poten-\n",
    "tial intrinsic bias. On the other hand, only a couple of other\n",
    "methods were designed for de novo translatome annota-\n",
    "tion by directly assessing the 3-nt periodicity, and these in-\n",
    "clude the strategy of ORFscore (11), RiboTaper (18) and\n",
    "\n",
    "and PRICE\n",
    "\n",
    "RP-BP (22). In the present study, we have developed a\n",
    "new statistically vigorous method, RiboCode, for the de\n",
    "novo annotation of the full translatome by quantitatively\n",
    "assessing the 3-nt periodicity (Figure 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Workflow Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2.4 The rpbp pipeline step-by-step:\n",
    "        - Creating reference genome indices;\n",
    "        - Running the pipeline: creating ORF profiles, predicting translated ORFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 2 QC IN>TRO\n",
    "\n",
    "\n",
    "\n",
    "Pre-Processing and Quality Control\n",
    "A characteristic feature of a high-quality Ribo-seq library is its distinct read-length distribution,\n",
    "which usually peaks at \u000229 nt in eukaryotic cytosolic ribosomes, reflecting the size of a\n",
    "translating ribosome on the RNA [10]. A broader distribution of reads has been observed in\n",
    "variants of the protocol, depending on the nuclease treatment [26]. An additional shorter\n",
    "footprint of \u000220 nt can be detected when performing Ribo-seq in absence of CHX or in\n",
    "\n",
    "presence of different inhibitors [29]. Distinct read-length distributions can also correspond to\n",
    "other ribosomal conformations [30] or to ribosomes belonging to different subcellular compart-\n",
    "ments. Mitochondrial ribosomes have been shown to display a bimodal distribution of read\n",
    "lengths, peaking at 27 and 33 nt, thus showing a clear difference when compared to cytosolic-\n",
    "derived RPFs [21] (Figure 1A).\n",
    "\n",
    "Beyond Read-Counts:\n",
    "Ribo-seq Data Analysis to\n",
    "Understand the Functions of\n",
    "the Transcriptome\n",
    "Lorenzo Calviello1,2 and Uwe Ohler\n",
    "\n",
    "\n",
    "\n",
    "Depending on the efficiency of the rRNA removal step, a high percentage of\n",
    "reads consists of small structured RNAs (rRNAs, tRNAs, or snoRNAs), which should be\n",
    "removed because their overabundance can skew subsequent quantification. As we are\n",
    "sequencing a pool of RNA fragments, a splice-aware alignment such as STARix [32] or\n",
    "others [33] can be used. RPFs are short (\u000229 nt), and many reads will map to multiple\n",
    "locations. To solve this, different ‘rescue’ strategies are used in popular RNA-seq quantifi-\n",
    "cation tools [34,35], but they are typically embedded inside a larger workflow for transcript\n",
    "quantification. Alternatively, the alignments can be filtered either by using specific tools [36] or\n",
    "by extracting one primary alignment per read [16]. In a high-quality Ribo-seq library, reads\n",
    "mostly map to coding sequence (CDS) regions (usually >85%) and 50 -UTRs (\u00025–10%), and\n",
    "0very few to 3 -UTRs (Figure 1B). Signals coming from introns and intergenic regions are\n",
    "usually the result of multi-mapping fragments.\n",
    "\n",
    "\n",
    "The distribution of aligned Ribo-seq reads over the translated ORFs is dependent on the\n",
    "kinetics of the translation process: the assembly of the initiation complex is a relatively slow\n",
    "process, resulting in a pronounced accumulation of signal around the start codon. In most\n",
    "datasets an additional accumulation can be observed at the last codon of the ORF, caused\n",
    "by the slow kinetics of translation termination and peptide release. In aggregate profiles of\n",
    "RPF 50 ends over annotated start and stop codons, it is possible to appreciate the single-\n",
    "nucleotide resolution of Ribo-seq data (Figure 1C): in most datasets, especially the more\n",
    "recent ones [11,12,16,37], 50 ends accumulate on one of the possible three frames, thus\n",
    "revealing the translated frame. This level of resolution at the subcodon level is usually\n",
    "accompanied by a distinct offset of the 50 ends relative to the annotated start codons\n",
    "(\u000212 nt for many datasets). This distance can be used to shift the positions of Ribo-seq\n",
    "reads and monitor translation at each translated codon, reflecting the positions of the P-site\n",
    "compartment for millions of ribosomal footprints. Aggregate profiles can drastically vary\n",
    "between different read lengths.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\n",
       "\\begin{align}\n",
       "a && b && c \\\\\n",
       "1 && 2 && 3\n",
       "\\end{align}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\n",
    "\\begin{align}\n",
    "a && b && c \\\\\n",
    "1 && 2 && 3\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "#################################\n",
    "#################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG    : Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# graphics\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set({\"ytick.direction\": u'out'}, style='ticks')\n",
    "\n",
    "params = {\n",
    "   'axes.labelsize': 26,\n",
    "   'font.size': 26,\n",
    "   'legend.fontsize': 26,\n",
    "   'xtick.labelsize': 24,\n",
    "   'ytick.labelsize': 24,\n",
    "   'text.usetex': True,\n",
    "   'figure.figsize': [12, 8],\n",
    "    'font.family': 'sans-serif',\n",
    "    'font.sans-serif': 'DejaVu Sans',\n",
    "    'mathtext.fontset': 'dejavusans'\n",
    "   }\n",
    "plt.rcParams.update(params)\n",
    "font = FontProperties().copy()\n",
    "\n",
    "mpl_logger = logging.getLogger('matplotlib')\n",
    "mpl_logger.setLevel(logging.WARNING) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MIT License\n",
    "\n",
    "Copyright (c) 2019 Etienne Boileau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
