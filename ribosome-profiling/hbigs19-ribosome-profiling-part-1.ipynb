{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1.1: Virtual environments and installation of packages hosted on GitHub\n",
    "\n",
    "## Sections:\n",
    "   - 1.1.1 Short introduction to Python virtual environments: how does a virtual environments work, installing and using a virtual environment.\n",
    "   - 1.1.2 Installation of packages hosted on GitHub.\n",
    "   - 1.1.3 Short introduction to Jupyter (Notebook) and the JupyterHub\n",
    "   \n",
    "## Questions & Objectives:\n",
    "   - Why do we need a virtual environment?\n",
    "   - Learn how to install and use a Python virtual environment.\n",
    "   - Learn how to install a package hosted on GitHub, in particular how to install the rpbp package.\n",
    "   - Jupyter Notebook basics: dashboard, user interface, navigation, running code, etc. How to use Jupyter with virtual environments.\n",
    "   - How to use the JupyterHub.\n",
    "   \n",
    "### After I will be able to:\n",
    "   - create and use a Python virtual environment to install packages.\n",
    "   - understand what is a Jupyter Notebook, and how to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1.1 Short introduction to Python virtual environments\n",
    "\n",
    "A *virtual environment* is a tool to help you keep dependencies and packages required by different projects separate and isolated from the system-wide installation.\n",
    "\n",
    "### Why do we need a virtual environment? \n",
    "    \n",
    "Imagine a scenario where you need different versions of the same package, say v1.8 and v2.5. These would normally reside in the same directory with the same name...\n",
    "\n",
    "    Virtual environments enable to isolate different versions of the same package (if they live in different environments, say myproject1.8 and myproject2.5).\n",
    "    \n",
    "Imagine a scenario where things go wrong (you break something, install many conflicting packages) ... \n",
    "\n",
    "    Virtual environments can be deleted and re-created easily without affecting your system or the other packages that are installed outside.\n",
    "    \n",
    "Imagine a scenario where you cannot install packages system-wide or do not want to do it...\n",
    "\n",
    "    Virtual environments enable you to install everything that you want, without affecting the system or other packages that are installed outside.\n",
    "    \n",
    "    \n",
    "### How does a virtual environment work?\n",
    "\n",
    "We use a module named `venv` which is a tool to create isolated Python environments. A virtual environment is a directory tree (a folder structure) which contains Python executables and other necessary files. These are ideally isolated from system site directories. Each virtual environment has its own Python installation and can have its own independent set of installed Python packages.\n",
    "\n",
    "When working in a command shell, to create a virtual environment (assuming you have Python3 installed!):\n",
    "\n",
    "`\n",
    "python3 -m venv /path/to/new/virtual/environment\n",
    "`\n",
    " \n",
    "To activate the new virtual environment:\n",
    "\n",
    "`\n",
    "source /path/to/virtual/environment/bin/activate\n",
    "`\n",
    "\n",
    "### Let's try it!\n",
    "\n",
    "We will create a fresh virtual environment and eventually install packages using the script `ribo-setup`, located\n",
    "under *hbigs_course_2019/ribosome-profiling*.\n",
    "\n",
    "\n",
    "### More\n",
    "\n",
    "- For information about Python virtual environments, see the [venv](https://docs.python.org/3/library/venv.html#module-venv) documentation. See also [PEP 405](https://www.python.org/dev/peps/pep-0405/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1.2 Installation of packages hosted on GitHub\n",
    "\n",
    "### What is GitHub?\n",
    "\n",
    "Git is an open-source version control system, *i.e.* used to track changes to documents/code for yourself or amongst collaborators, releasing versions, *etc.* GitHub.com is where (mostly) developers store their projects, and render them accessible to the community. Anyone (even people who have nothing to do with the development of a project) can download the files and use them (according to the license, *e.g* the `rpbp` package, as well as these notebooks/scripts and the original material for this part of the course is under the MIT license). Project files are\n",
    "stored in a particular location, referred to as a repository (usually abbreviated to *repo*), and you can access it with a unique URL. \n",
    "\n",
    "### How to install a package hosted on GitHub?\n",
    "\n",
    "Some packages hosted on GitHub can be installed via package-management systems (`pip` for Python, RStudio Package Manager, *etc.*). In these cases, you may not even know that the source codes for these packages \"live\" on GitHub. Sometimes, however, you need to install the package by first *cloning* the repository and following specific instructions.\n",
    "\n",
    "![](img/git-1.png)\n",
    "\n",
    "\n",
    "### Let's try it!\n",
    "\n",
    "After creating a new virtual environment for this part of the course, we will install the `rpbp` and `slurm-magic` packages using the script `ribo-setup`, located under *hbigs_course_2019/ribosome-profiling*.\n",
    "\n",
    "\n",
    "### More\n",
    "\n",
    "- In the last part of the course, we will go through a collection of explanations and short practical exercises about version control (Git and GitHub) and open source software. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1.3 Short introduction to Jupyter (Notebook) and the JupyterHub\n",
    "\n",
    "The Jupyter Notebook is an open-source web-based application allowing in-browser editing (Jupyter is running on your own computer, *i.e* your computer acts as the server), combining text, code, computations and rich media output (notebook documents). Jupyter supports many programming languages, including Python, R, and Julia. The JupyterHub is a multi-user version of the Notebook (this notebook is served via \"our Hub\" `https://jupyter.dieterichlab.org:49200`).\n",
    "\n",
    "### Basic workflow\n",
    "\n",
    "Typically, a notebook document is organised into cells, and one moves forward from one cell to the next, breaking the content or the computation into separate parts. This workflow allows to \"validate\" the output of one cell before moving to the next, and is also convenient for interactive exploration.\n",
    "\n",
    "### Jupyter Notebook basics\n",
    "\n",
    "The Notebook dashboard: when you first start the notebook server, your browser will open to the notebook dashboard. To create a new notebook, click on the \"New\" button and select a kernel from the dropdown menu. The running notebooks are shown with a green icon and text (or via the \"Running tab\"). Notebooks remain running until you explicitly shut them down; closing the notebook's page is not sufficient. \n",
    "   \n",
    "![](img/jupyter-1.png)\n",
    "    \n",
    "To shutdown, delete, duplicate, or rename a notebook check the checkbox next to it. You can also perform these operations and more directly on the running notebook by using the top menu and tool bar (see at the top of this notebook!) \n",
    "\n",
    "![](img/jupyter-2.png)\n",
    "\n",
    "Modal editor: **edit mode**. Edit mode is indicated by a green cell border and a prompt showing in the editor area. When a cell is in edit mode, you can type into the cell, like a normal text editor. Enter edit mode by pressing `Enter` or using the mouse to click on a cell.\n",
    "\n",
    "![](img/jupyter-3.png)\n",
    "\n",
    "Modal editor: **command mode**. Command mode is indicated by a grey cell border with a blue left margin. When you are in command mode, you are able to edit the notebook as a whole, but not type into individual cells (be careful to type into a cell in command mode!). Enter command mode by pressing `Esc` or using the mouse to click outside a cell.\n",
    "    \n",
    "![](img/jupyter-4.png)\n",
    "\n",
    "### Basic commands\n",
    "\n",
    "Edit mode\n",
    "\n",
    "| Command | action |\n",
    "|------|------|\n",
    "|   `Ctrl-Enter`  | run selected cells |\n",
    "|   `Shift-Enter`  | run cell, select below |\n",
    "\n",
    "Command mode\n",
    "\n",
    "| Command | action |\n",
    "|------|------|\n",
    "|   `Enter`  | enter edit mode |\n",
    "|   `Esc`  | enter command mode |\n",
    "|   `a`  | insert cell above |\n",
    "|   `b`  | insert cell below |\n",
    "\n",
    "\n",
    "## More\n",
    "\n",
    "- See [Project Jupyter](https://jupyter.org/) for installation instructions, detailed documentation, *etc.*\n",
    "- After the course, explore the menu (Help) of this notebook, and experiment with basic commands.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use Jupyter with virtual environments\n",
    "\n",
    "We will now go back to your Desktop, open an `LXTerminal` and navigate to the directory for this part of the course by typing: \n",
    "\n",
    "`\n",
    "cd hbigs_course_2019/ribosome-profiling\n",
    "`\n",
    "\n",
    "You will see there this notebook and others, as well as a file called `ribo-setup`. We will run this script to create a new virtual ennvironment, clone the `rprp` and `slurm-magic` repositories, install the packages and add a jupyter kernel for the newly created environment. When the script has finished running, we will need to (1) refresh the page, (2) go to \"Kernel\" in the top menu bar, (3) \"Change kenerl\" in the dropdown menu list, and then select `hbigs19-ribo`, which is the name of our newly created environment.\n",
    "\n",
    "![](img/jupyter-5.png)\n",
    "\n",
    "\n",
    "We are now ready to go...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1.2: Introduction to ribosome-profiling (Ribo-seq) and the Rp-Bp workflow\n",
    "\n",
    "For practical reasons, we will cover some technical aspects before introducing ribosome-profiling in more details. In particular, we will first set-up our notebook to run `rpbp` on the example Ribo-seq dataset, briefly introduce the SLURM workload manager (via `slurm-magic`), and actually run the `rpbp` pipeline. While our data is running, we will then go into more details about Ribo-seq, the `rpbp` package and some methodological aspects behind it.\n",
    "\n",
    "\n",
    "\n",
    "    - Sections:\n",
    "        - High-level introduction to Ribo-seq, de novo ORF discovery (elements of annotation, \n",
    "        transcript isoforms, CDS, UTRs, etc.), biological relevance of \n",
    "        alternative translation events (including translation from non-coding transcripts), \n",
    "        and why we need \"dedicated software\" to analyse Ribo-seq data.\n",
    "        - Very short introduction to the SLURM workload manager (slurm-magic), used\n",
    "        to run the rpbp pipeline.\n",
    "        - The rpbp pipeline step-by-step:\n",
    "            - Creating reference genome indices;\n",
    "            - Running the rpbp pipeline: creating ORF profiles, predicting\n",
    "            translated ORFs.\n",
    "    - Duration:\n",
    "        - 1 hour 30 min. to 2 hours.\n",
    "    - Questions & Objectives:\n",
    "        - What is the translatome? What are the uses of Ribo-seq.\n",
    "        - Why do we need dedicated software to analyse Ribo-seq data?\n",
    "        - What softwares are available to analyse Ribo-seq data?\n",
    "        - Understand how to use the rpbp package (on my laptop, on the cluster using\n",
    "        the SLURM workload manager).\n",
    "        - Run the complete rpbp pipeline on a selected Ribo-seq dataset.\n",
    "    - After I will be able to:\n",
    "        - understand how to analyse Ribo-seq data for ORF discovery;\n",
    "        - run the rpbp package (only ORF profiles, or full pipeline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open console, explain script, run script\n",
    "# while running, open jupyter hub, login, and open notebook part 1\n",
    "\n",
    "# part1: virtual environments (try also from console), jupyter notebooks (what is it, basic commands, etc.)\n",
    "# and slurm (cluster): quick cell what to do if you want to do that from your PC at home (RTD, script, no need for\n",
    "# notebooks in the end, etc.)\n",
    "# now, add kernel and change: we have access to what we installed\n",
    "# lastly, add what is needed to our path, we are now ready\n",
    "\n",
    "# intro riboseq, rp-bp (practical, workflow), from RTD, etc. expand based on workflow demo for ribo-seq\n",
    "# explain index creation, skip index, show where it is, and what it consists of\n",
    "# prepare to run the example dataset, submit, a bit of slurm\n",
    "# while running, extend on rp-bp, what it does in more details (RTD and paper, some background theory, etc.)\n",
    "# in particular explain that we have changed params, but normally no, etc.\n",
    "# when complete, run report (more is coming than pdf report...)\n",
    "\n",
    "# part2: QC existing full results (prepare data before) (my git), maybe not all, but some plots...\n",
    "# show some tables and plots\n",
    "# exercice: use the example dataset and try the QC by repeating the steps\n",
    "\n",
    "# part3: TE overview (need to run beforehand full dataset here they cannot run it, not \n",
    "# installed on their virtual environment), theoretical background, some code hints, etc.\n",
    "# then load tables/results and explore (create MD plot, volcano plot, etc.)\n",
    "# also have a look at Glimma (R), open plot and see.\n",
    "\n",
    "# EXTRA:...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO\n",
    "\n",
    "# set license on all material, see license on git material, explain to them\n",
    "\n",
    "# try full install, jupyter hub, switch and run example from course01\n",
    "# run report\n",
    "# run htseq, Deseq\n",
    "\n",
    "\n",
    "# remove downsample analysis from ref folder, but run it on course01 and leave it there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jupyter notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# virtual environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slurm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic hopw to if on your own laptop, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules that are needed to run this notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some functions, definitions, etc. that are needed to run this notebook\n",
    "\n",
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "@register_line_cell_magic\n",
    "def writefile_globals(line, cell):\n",
    "    with open(line, 'w') as f:\n",
    "        f.write(cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sbin:/usr/sbin:/bin:/usr/bin:/usr/local/bin\r\n"
     ]
    }
   ],
   "source": [
    "# $PATH is an environment variable related to file location that are typically used to run programs.\n",
    "# When one types a command to run, the system looks for this command in the directories specified by $PATH.\n",
    "\n",
    "# What is on you $PATH?\n",
    "!echo $PATH \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/sbin:/usr/sbin:/bin:/usr/bin:/usr/local/bin:/biosw/slurm/18.08.6.2/bin:/biosw/bowtie2/2.3.0:/biosw/star/2.6.1d:/biosw/samtools/1.7/bin:/biosw/flexbar/3.5.0:/home/eboileau/hbigs_course_2019/ribosome-profiling/envs/hbigs19-ribo/bin\n"
     ]
    }
   ],
   "source": [
    "# We will now add the location of certain programs that are required to our $PATH,\n",
    "# including executable scripts that were installed with the rpbp package.\n",
    "\n",
    "# Advanced note: sys.path does not contain path to virtual environment executables, and adding to sys.path\n",
    "# does not solve the problem...\n",
    "\n",
    "# first find where we are, we use the same structure as in \"ribo-setup\" \n",
    "HOME = !echo $HOME\n",
    "HOME = HOME.n\n",
    "PARENT = HOME + '/hbigs_course_2019/ribosome-profiling'\n",
    "# this is the location where rpbp-related executables were installed\n",
    "ENVLOC = PARENT + '/envs/hbigs19-ribo/bin'\n",
    "# these are standard bioinformatics tools that you have already used, which are installed\n",
    "# at these locations on the cluster, we use specific versions to be compatible with the rpbp package\n",
    "add2path = ['/biosw/slurm/18.08.6.2/bin',\n",
    "            '/biosw/bowtie2/2.3.0',\n",
    "            '/biosw/star/2.6.1d',\n",
    "            '/biosw/samtools/1.7/bin',\n",
    "            '/biosw/flexbar/3.5.0']\n",
    "add2path.append(ENVLOC)\n",
    "\n",
    "PATH = !echo $PATH\n",
    "PATH.extend(add2path)\n",
    "PATH = ':'.join(PATH)\n",
    "# out updated $PATH is...\n",
    "%set_env PATH=$PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intro riboseq, rp-bp (practical, workflow), from RTD, etc. expand based on workflow demo for ribo-seq\n",
    "# explain index creation, skip index, show where it is, and what it consists of\n",
    "\n",
    "# intro rpbp run-merge all, etc. i.e. what we do below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/home/eboileau/riboSeqHBIGS19-downsampled-analysis/config'\n",
      "/beegfs/pub/hbigs_course_2019/ribosome-profiling\n"
     ]
    }
   ],
   "source": [
    "# Prepare to run the example (downsampled) dataset: 4 replicates, 2 PBS, 2 EGF.\n",
    "# change directory\n",
    "DIRLOC = '/riboSeqHBIGS19-downsampled-analysis'\n",
    "CFG = HOME + DIRLOC + '/config'\n",
    "RES = HOME + DIRLOC + '/riboseq-results'\n",
    "%cd $CFG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first need to prepare a YAML configuration file to run the rpbp package. \n",
    "# YAML (\"YAML Ain't Markup Language\") is a data-serialization (markup) language.\n",
    "\n",
    "# We will do this below and explain the structure of the config file. Please check that\n",
    "# the file has been correctly written to disk under /riboSeqHBIGS19-downsampled-analysis/config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile_globals hbigs19-downsampled.yaml\n",
    "\n",
    "project_name: HBIGS19-downsampled\n",
    "\n",
    "# Base location for the created index files.=\n",
    "genome_base_path: /beegfs/pub/hbigs_course_2019/ribosome-profiling/genomes/homo_sapiens/GRCh38_96\n",
    "    \n",
    "# An identifier which will be used in the filenames. This should not contain\n",
    "# spaces, forward slashes, or other special characters.\n",
    "genome_name: GRCh38.96\n",
    "    \n",
    "# The full path to the GTF file which contains the exon and CDS annotations.\n",
    "gtf: /beegfs/pub/hbigs_course_2019/ribosome-profiling/genomes/homo_sapiens/GRCh38_96/GRCh38.96.gtf\n",
    "\n",
    "# The fasta file which contains the genome. The genomic identifiers in the GTF and\n",
    "# fasta files must match (e.g., \"I\" and \"I\", or \"chrI\" and \"chrI\", but not \"I\" and \"chrI\").\n",
    "fasta: /beegfs/pub/hbigs_course_2019/ribosome-profiling/genomes/homo_sapiens/GRCh38_96/GRCh38_96.fa\n",
    "\n",
    "# The base location for the STAR genome index.\n",
    "star_index: /beegfs/pub/hbigs_course_2019/ribosome-profiling/genomes/homo_sapiens/GRCh38_96/star\n",
    "\n",
    "# The base location for the Bowtie2 index for the ribosomal sequences.\n",
    "ribosomal_index: /beegfs/pub/hbigs_course_2019/ribosome-profiling/genomes/homo_sapiens/rRNA_cluster_plus_mtRNA/rRNA_cluster_plus_mtRNA\n",
    "# The fasta file containing the rRNA sequences. The file can also contain other\n",
    "# sequences which should be filtered, such as tRNA or snoRNAs\n",
    "ribosomal_fasta: /beegfs/pub/hbigs_course_2019/ribosome-profiling/genomes/homo_sapiens/rRNA_cluster_plus_mtRNA/rRNA_cluster_plus_mtRNA.fasta\n",
    "\n",
    "# A file containing standard adapters.\n",
    "adapter_file: /beegfs/pub/hbigs_course_2019/ribosome-profiling/genomes/riboseq-adapters.fa\n",
    "\n",
    "# The base location for the created files\n",
    "riboseq_data: {RES}\n",
    "\n",
    "# A dictionary in which each entry specifies a sample. The key is an \n",
    "# informative name about the sample, and the value gives the complete path to \n",
    "# the sequencing file (a fastq(.gz) file). The names will be used to \n",
    "# construct filenames, so they should not contain spaces, forward slashes, or \n",
    "# other special characters.\n",
    "riboseq_samples:\n",
    " dSRR7451194.EGF.rep-1: /beegfs/pub/hbigs_course_2019/raw-data/downsampled/dSRR7451194_1.fastq.gz\n",
    " dSRR7451184.EGF.rep-2: /beegfs/pub/hbigs_course_2019/raw-data/downsampled/dSRR7451184_1.fastq.gz\n",
    " dSRR7451191.PBS.rep-1: /beegfs/pub/hbigs_course_2019/raw-data/downsampled/dSRR7451191_1.fastq.gz\n",
    " dSRR7451197.PBS.rep-2: /beegfs/pub/hbigs_course_2019/raw-data/downsampled/dSRR7451197_1.fastq.gz\n",
    "\n",
    "riboseq_biological_replicates:\n",
    " EGF:\n",
    "  - dSRR7451194.EGF.rep-1\n",
    "  - dSRR7451184.EGF.rep-2\n",
    " PBS:\n",
    "  - dSRR7451191.PBS.rep-1\n",
    "  - dSRR7451197.PBS.rep-2\n",
    "\n",
    "riboseq_sample_name_map:\n",
    " dSRR7451194.EGF.rep-1: EGF1\n",
    " dSRR7451184.EGF.rep-2: EGF2\n",
    " dSRR7451191.PBS.rep-1: PBS1\n",
    " dSRR7451197.PBS.rep-2: PBS2\n",
    "\n",
    "# Rp-Bp options: we need to change the default parameters to run the downsampled data.\n",
    "# Generally, you do not need to change the default parameters!\n",
    "\n",
    "# The number of bases upstream of the translation initiation site to begin \n",
    "# constructing the metagene profile.\n",
    "metagene_start_upstream: 50\n",
    "# The number of bases downstream of the translation initiation site to end \n",
    "# the metagene profile.\n",
    "metagene_start_downstream: 50\n",
    "# The number of bases upstream of the translation termination site to begin \n",
    "# constructing the metagene profile.\n",
    "metagene_end_upstream: 50\n",
    "# The number of bases downstream of the translation termination site to end \n",
    "# the metagene profile.\n",
    "metagene_end_downstream: 50\n",
    "\n",
    "# N.B. These values are set artificially low for the example to work!\n",
    "min_metagene_profile_count: 50\n",
    "min_metagene_image_count: 10\n",
    "\n",
    "# N.B. These value are set low to reduce the running time, but will affect the results.\n",
    "metagene_iterations: 100\n",
    "translation_iterations: 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are now ready to submit our job. We use the slurm workload manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Submitted batch job 336179\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH -J \"hbigs19\"\n",
    "#SBATCH -n 1\n",
    "#SBATCH -N 1\n",
    "#SBATCH -c 1\n",
    "#SBATCH --mem=20G\n",
    "\n",
    "run-all-rpbp-instances hbigs19-downsampled.yaml \\\n",
    "    --merge-replicates \\\n",
    "    --run-replicates \\\n",
    "    --keep-intermediate-files \\\n",
    "    --num-cpus 12 \\\n",
    "    --use-slurm \\\n",
    "    --logging-level INFO \\\n",
    "    --log-file hbigs19-downsampled.log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "initial_value must be str or None, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-785c7d2f3135>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# We check that our job is actually running...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'squeue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'#-u #course01'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/rpbp-master-161019/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2312\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2313\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2314\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2315\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/rpbp-master-161019/lib/python3.6/site-packages/slurm_magic.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(obj, line)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_display\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pandas\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             return pandas.read_table(io.StringIO(result), sep='\\s+',\n\u001b[0m\u001b[1;32m     22\u001b[0m                     error_bad_lines=False)\n\u001b[1;32m     23\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: initial_value must be str or None, not tuple"
     ]
    }
   ],
   "source": [
    "# We check that our job is actually running...\n",
    "%squeue -u course01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while running, extend on rp-bp, what it does in more details (RTD and paper, some background theory, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\n",
       "\\begin{align}\n",
       "a && b && c \\\\\n",
       "1 && 2 && 3\n",
       "\\end{align}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\n",
    "\\begin{align}\n",
    "a && b && c \\\\\n",
    "1 && 2 && 3\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import logging\n",
    "\n",
    "import itertools\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import Bio.Seq\n",
    "from Bio import SeqIO\n",
    "\n",
    "import pbio.utils.bed_utils as bed_utils\n",
    "import pbio.misc.utils as utils\n",
    "\n",
    "import pbio.misc.parallel as parallel\n",
    "import pbio.misc.pandas_utils\n",
    "\n",
    "import pbio.ribo.ribo_utils as ribo_utils\n",
    "import pbio.ribo.ribo_filenames as filenames\n",
    "\n",
    "import pbio.misc.logging_utils as logging_utils\n",
    "logger = logging_utils.get_ipython_logger()\n",
    "\n",
    "from argparse import Namespace\n",
    "args = Namespace()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext slurm_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "#################################\n",
    "#################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG    : Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# graphics\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set({\"ytick.direction\": u'out'}, style='ticks')\n",
    "\n",
    "params = {\n",
    "   'axes.labelsize': 26,\n",
    "   'font.size': 26,\n",
    "   'legend.fontsize': 26,\n",
    "   'xtick.labelsize': 24,\n",
    "   'ytick.labelsize': 24,\n",
    "   'text.usetex': True,\n",
    "   'figure.figsize': [12, 8],\n",
    "    'font.family': 'sans-serif',\n",
    "    'font.sans-serif': 'DejaVu Sans',\n",
    "    'mathtext.fontset': 'dejavusans'\n",
    "   }\n",
    "plt.rcParams.update(params)\n",
    "font = FontProperties().copy()\n",
    "\n",
    "mpl_logger = logging.getLogger('matplotlib')\n",
    "mpl_logger.setLevel(logging.WARNING) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "######################################################\n",
    "######################################################\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MIT License\n",
    "\n",
    "Copyright (c) 2019 Etienne Boileau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "rpbp-master-161019",
   "language": "python",
   "name": "rpbp-master-161019"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
